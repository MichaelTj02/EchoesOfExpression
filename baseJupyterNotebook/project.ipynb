{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.66.3)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (11.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.13 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.13 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.32.2)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.49.0)\n",
      "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.15.2)\n",
      "Requirement already satisfied: safetensors in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.5.3)\n",
      "Requirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from diffusers) (8.6.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from diffusers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from diffusers) (0.29.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from diffusers) (2.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from diffusers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from diffusers) (11.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.23.2->diffusers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (75.5.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->diffusers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->diffusers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->diffusers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->diffusers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.13 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install diffusers transformers accelerate scipy safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.13 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (4.6.2.post1)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Downloading audioop_lts-0.2.1-cp313-abi3-macosx_11_0_arm64.whl.metadata (1.6 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio)\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (0.29.3)\n",
      "Requirement already satisfied: jinja2<4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (2.1.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.16-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (2.10.6)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.11.2-py3-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.8.0->gradio)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.2.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading audioop_lts-0.2.1-cp313-abi3-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading orjson-3.10.16-cp313-cp313-macosx_15_0_arm64.whl (133 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.2-py3-none-macosx_11_0_arm64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, uvicorn, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, mdurl, groovy, ffmpy, audioop-lts, aiofiles, starlette, markdown-it-py, safehttpx, rich, gradio-client, fastapi, typer, gradio\n",
      "Successfully installed aiofiles-23.2.1 audioop-lts-0.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.16 pydub-0.25.1 python-multipart-0.0.20 rich-13.9.4 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.46.1 tomlkit-0.13.2 typer-0.15.2 uvicorn-0.34.0 websockets-15.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.13 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Initialize OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# For API keys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Open AI GPT-4\n",
    "import openai\n",
    "\n",
    "# Handwriting OCR\n",
    "import cv2\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "# For sentiment analysis\n",
    "import json\n",
    "import re\n",
    "\n",
    "# For stable diffusion\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# For canvas and drawing\n",
    "from PIL import Image\n",
    "import random\n",
    "from IPython.display import display, clear_output\n",
    "import time # For live drawing\n",
    "from collections import deque\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # load .env file to get API KEY\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check if API key is loaded\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"API Key not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client \n",
    "client = openai.OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key Loaded Successfully!\n",
      "ChatGPT Response: Hello! How can I assist you with your Jupyter Notebook today? Whether you need help with coding, data analysis, visualizations, or something else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Test API call with the updated function\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello from Jupyter Notebook!\"}]\n",
    ")\n",
    "\n",
    "print(\"API Key Loaded Successfully!\")\n",
    "print(\"ChatGPT Response:\", response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Drawing Agents (Reactive Systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, image, start_x, start_y, patch_size=5):\n",
    "        self.image = image.convert(\"RGBA\")  # Ensure image has alpha\n",
    "        self.patch_size = patch_size\n",
    "        self.origin_x = start_x\n",
    "        self.origin_y = start_y\n",
    "        self.visited = set()\n",
    "        self.queue = deque()\n",
    "\n",
    "        # Drawing mode determines shape of reveal\n",
    "        self.drawing_mode = random.choice([\n",
    "            \"center_out\", \n",
    "            \"top_down\", \n",
    "            \"left_to_right\", \n",
    "            \"spiral\", \n",
    "            \"organic_noise\"\n",
    "        ])\n",
    "\n",
    "        center_x = self.origin_x + self.image.width // 2\n",
    "        center_y = self.origin_y + self.image.height // 2\n",
    "\n",
    "        if self.drawing_mode == \"center_out\" or self.drawing_mode == \"spiral\":\n",
    "            self.queue.append((center_x, center_y))\n",
    "\n",
    "        elif self.drawing_mode == \"top_down\":\n",
    "            for x in range(self.origin_x, self.origin_x + self.image.width, self.patch_size):\n",
    "                self.queue.append((x, self.origin_y))\n",
    "\n",
    "        elif self.drawing_mode == \"left_to_right\":\n",
    "            for y in range(self.origin_y, self.origin_y + self.image.height, self.patch_size):\n",
    "                self.queue.append((self.origin_x, y))\n",
    "\n",
    "        elif self.drawing_mode == \"organic_noise\":\n",
    "            for _ in range(10):\n",
    "                rx = random.randint(self.origin_x, self.origin_x + self.image.width - self.patch_size)\n",
    "                ry = random.randint(self.origin_y, self.origin_y + self.image.height - self.patch_size)\n",
    "                self.queue.append((rx, ry))\n",
    "\n",
    "    def update(self, canvas):\n",
    "        if not self.queue:\n",
    "            return\n",
    "\n",
    "        x, y = self.queue.popleft()\n",
    "        key = (x, y)\n",
    "        if key in self.visited:\n",
    "            return\n",
    "\n",
    "        self.visited.add(key)\n",
    "\n",
    "        # Get image patch\n",
    "        patch = self.image.crop((\n",
    "            max(0, x - self.origin_x),\n",
    "            max(0, y - self.origin_y),\n",
    "            max(0, x - self.origin_x + self.patch_size),\n",
    "            max(0, y - self.origin_y + self.patch_size)\n",
    "        ))\n",
    "\n",
    "        # Fade alpha based on distance from center\n",
    "        center_x = self.origin_x + self.image.width // 2\n",
    "        center_y = self.origin_y + self.image.height // 2\n",
    "        dist = ((x - center_x) ** 2 + (y - center_y) ** 2) ** 0.5\n",
    "        max_dist = ((self.image.width // 2) ** 2 + (self.image.height // 2) ** 2) ** 0.5\n",
    "        fade = max(0.2, 1.0 - (dist / max_dist))  # Avoid full transparency\n",
    "\n",
    "        patch = patch.copy()\n",
    "        r, g, b, a = patch.split()\n",
    "        a = a.point(lambda p: int(p * fade))\n",
    "        patch.putalpha(a)\n",
    "\n",
    "        canvas.paste(patch, (x, y), patch)\n",
    "\n",
    "        # Base directions (4-neighbors)\n",
    "        directions = [\n",
    "            (self.patch_size, 0), (-self.patch_size, 0),\n",
    "            (0, self.patch_size), (0, -self.patch_size)\n",
    "        ]\n",
    "\n",
    "        # Modify expansion pattern\n",
    "        if self.drawing_mode == \"spiral\":\n",
    "            directions = sorted(directions, key=lambda d: random.random() + 0.3 * (d[0] + d[1]))\n",
    "\n",
    "        elif self.drawing_mode == \"top_down\":\n",
    "            directions = sorted(directions, key=lambda d: d[1])  # prioritize y (vertical)\n",
    "\n",
    "        elif self.drawing_mode == \"left_to_right\":\n",
    "            directions = sorted(directions, key=lambda d: d[0])  # prioritize x (horizontal)\n",
    "\n",
    "        elif self.drawing_mode == \"organic_noise\":\n",
    "            random.shuffle(directions)\n",
    "\n",
    "        # Expand to neighbors\n",
    "        for dx, dy in directions:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            if (nx, ny) not in self.visited:\n",
    "                if self.origin_x <= nx < self.origin_x + self.image.width - self.patch_size and \\\n",
    "                   self.origin_y <= ny < self.origin_y + self.image.height - self.patch_size:\n",
    "                    self.queue.append((nx, ny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Handwritten Text (OCR, Translation, and Emotion Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processing methods\n",
    "\n",
    "# Preprocess handwriting image to make it more legible\n",
    "def preprocess_handwriting(image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Apply adaptive thresholding (Binarization)\n",
    "    processed = cv2.adaptiveThreshold(\n",
    "        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "\n",
    "    # Save processed image\n",
    "    processed_path = \"processed_handwriting.jpg\"\n",
    "    cv2.imwrite(processed_path, processed)\n",
    "\n",
    "    return processed_path\n",
    "\n",
    "# Convert image to Base64\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "# Extract handwriting image\n",
    "def extract_text_from_handwriting(image_path):\n",
    "    base64_image = image_to_base64(image_path)  # Convert image to base64\n",
    "\n",
    "    try:\n",
    "        # Send request to OpenAI GPT-4o\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \n",
    "                            \"Extract the handwritten text from this image and detect its language.\"\n",
    "                            \"Return the result in JSON format: {\\\"text\\\": \\\"extracted text\\\", \\\"language\\\": \\\"detected language\\\"}.\"\n",
    "                            \"Do not add extra explanations, just return valid JSON.\"\n",
    "                        },\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "\n",
    "        raw_response = response.choices[0].message.content.strip()\n",
    "        # print(f\"\\n Raw GPT Response: {raw_response}\")  # Debugging Output\n",
    "\n",
    "        json_match = re.search(r\"\\{.*\\}\", raw_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_text = json_match.group(0)  # Extract JSON-only content\n",
    "        else:\n",
    "            raise ValueError(\"Invalid JSON format received from GPT.\")\n",
    "\n",
    "        # Parse cleaned JSON response\n",
    "        text_data = json.loads(json_text)\n",
    "        extracted_text = text_data.get(\"text\", \"Unknown\")\n",
    "        detected_language = text_data.get(\"language\", \"Unknown\")\n",
    "\n",
    "        return extracted_text, detected_language\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI API Error: {e}\")\n",
    "        return None, \"Unknown\"\n",
    "    \n",
    "# Detect language & translate to English using GPT-4o\n",
    "def translate_to_english(text):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": f\"Detect the language of this text: '{text}'. If it's not English, translate it to English. If it's already in English, return the same text.\"}\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "\n",
    "        translated_text = response.choices[0].message.content.strip()\n",
    "        # print(f\"\\n Translated Text (English): {translated_text}\")  # Debugging output\n",
    "        return translated_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Translation Error: {e}\")\n",
    "        return text  # If translation fails, return original text\n",
    "    \n",
    "# Analyze emotion\n",
    "def analyze_emotion(text):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": f\"Analyze the following text: '{text}'. \"\n",
    "                 \"Return ONLY a JSON object with the following structure: \"\n",
    "                 \"{{\\\"emotion\\\": \\\"Happiness\\\", \\\"confidence\\\": 0.92, \\\"language\\\": \\\"English\\\"}}. \"\n",
    "                 \"The 'emotion' should be one of: Happiness, Sadness, Fear, Anger, Surprise, or Disgust. \"\n",
    "                 \"The 'confidence' should be a float between 0 and 1. \"\n",
    "                 \"The 'language' should be a single-word language name (e.g., English, Japanese, Chinese). \"\n",
    "                 \"No explanations, no extra text—return only a valid JSON output.\"}\n",
    "            ],\n",
    "            max_tokens=100\n",
    "        )\n",
    "\n",
    "        raw_response = response.choices[0].message.content.strip()\n",
    "        # print(f\"\\n Raw GPT Response: {raw_response}\")  # Debugging output\n",
    "\n",
    "        # Extract JSON using regex if there's extra text\n",
    "        json_match = re.search(r\"\\{.*\\}\", raw_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_text = json_match.group(0)  # Extracts the JSON part only\n",
    "        else:\n",
    "            raise ValueError(\"Invalid JSON format received from GPT.\")\n",
    "\n",
    "        # Parse JSON safely\n",
    "        text_analysis_data = json.loads(json_text)\n",
    "\n",
    "        # Extract emotion, confidence, and language\n",
    "        detected_emotion = text_analysis_data.get(\"emotion\", \"Unknown\")\n",
    "        confidence_score = text_analysis_data.get(\"confidence\", 0.0)\n",
    "        detected_language = text_analysis_data.get(\"language\", \"Unknown\")\n",
    "\n",
    "        return {\n",
    "            \"emotion\": detected_emotion,\n",
    "            \"confidence\": confidence_score,\n",
    "            \"language\": detected_language\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Text Analysis Error: {e}\")\n",
    "        return {\n",
    "            \"emotion\": \"Unknown\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"language\": \"Unknown\"\n",
    "        }\n",
    "        \n",
    "def process_handwritten_image(processed_image):\n",
    "    global extracted_data  # Declare global variable\n",
    "    \n",
    "    extracted_text, detected_language = extract_text_from_handwriting(processed_image)\n",
    "\n",
    "    if extracted_text:\n",
    "        translated_text = translate_to_english(extracted_text) if detected_language.lower() != \"english\" else extracted_text\n",
    "        text_analysis_data = analyze_emotion(translated_text)\n",
    "\n",
    "        detected_emotion = text_analysis_data[\"emotion\"]\n",
    "        confidence_score = text_analysis_data[\"confidence\"]\n",
    "\n",
    "        # Store data in the global variable\n",
    "        extracted_data = {\n",
    "            \"extracted_text\": extracted_text,\n",
    "            \"language\": detected_language,\n",
    "            \"translated_text\": translated_text,\n",
    "            \"emotion\": detected_emotion,\n",
    "            \"confidence\": confidence_score\n",
    "        }\n",
    "\n",
    "        # Print output\n",
    "        print(\"\\n Extracted Information Stored:\")\n",
    "        print(f\"Extracted Text: {extracted_data['extracted_text']}\")\n",
    "        print(f\"Detected Language: {extracted_data['language']}\")\n",
    "        print(f\"Translated Text: {extracted_data['translated_text'] if extracted_data['language'].lower() != 'english' else 'N/A'}\")\n",
    "        print(f\"Detected Emotion: {extracted_data['emotion']}\")\n",
    "        print(f\"Confidence Score: {extracted_data['confidence']:.2f}\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\n Failed to process the text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Emotion and Incorporate Culture from Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Composition mapping based on detected emotion, grammar system\n",
    "COMPOSITION_MAPPING = {\n",
    "    \"Happiness\": \"Symmetrical & Balanced\",\n",
    "    \"Sadness\": \"Soft, Scattered & Faded\",\n",
    "    \"Anger\": \"Chaotic & Overlapping\",\n",
    "    \"Fear\": \"Dark & Enclosed\",\n",
    "    \"Surprise\": \"Expanding & Explosive\",\n",
    "    \"Disgust\": \"Distorted & Melting\",\n",
    "    \"Unknown\": \"Abstract Freeform\"\n",
    "}\n",
    "\n",
    "def assign_composition_style():\n",
    "    \"\"\"Assigns a composition layout based on the detected emotion.\"\"\"\n",
    "    global extracted_data\n",
    "\n",
    "    detected_emotion = extracted_data.get(\"emotion\", \"Unknown\")\n",
    "    composition_style = COMPOSITION_MAPPING.get(detected_emotion, COMPOSITION_MAPPING[\"Unknown\"])\n",
    "\n",
    "    extracted_data[\"composition_style\"] = composition_style\n",
    "\n",
    "    # print(f\"Assigned Composition Style for {detected_emotion}: {composition_style}\") # Debug print\n",
    "    return composition_style\n",
    "\n",
    "# Determine visual goal depending on the language detected\n",
    "def get_visual_goal():\n",
    "    \"\"\"Uses GPT-4 to generate cultural visual goal based on detected language.\"\"\"\n",
    "    \n",
    "    global extracted_data\n",
    "    \n",
    "    detected_language = extracted_data.get(\"language\", \"Unknown\")\n",
    "    \n",
    "    if detected_language == \"Unknown\":\n",
    "        print(\"Language not detected\")\n",
    "        return \"Unknown cultural element\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in global art and culture.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Provide only **two or three words** that represent a traditional artistic style, symbol, or pattern from the culture associated with the {detected_language} language. Do not give explanations. Just return the keywords.\"}\n",
    "            ],\n",
    "            max_tokens=100\n",
    "        )\n",
    "\n",
    "        visual_goal = response.choices[0].message.content.strip()\n",
    "        \n",
    "        return visual_goal\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"GPT API Error: {e}\")\n",
    "        return \"Unknown cultural element\"\n",
    "    \n",
    "def fetch_cultural_prompt_info():\n",
    "    global extracted_data\n",
    "\n",
    "    detected_language = extracted_data.get(\"language\", \"Unknown\")\n",
    "\n",
    "    if detected_language == \"Unknown\":\n",
    "        print(\"Language not detected.\")\n",
    "        return {\n",
    "            \"culture\": detected_language,\n",
    "            \"art_form\": \"traditional art\",\n",
    "            \"motif\": \"cultural motif\",\n",
    "            \"script\": f\"{detected_language} script\"\n",
    "        }\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a cultural visual designer. Given a language, respond ONLY in raw JSON format with these 4 keys:\\n\"\n",
    "        \"'culture', 'art_form', 'motif', 'script'.\\n\"\n",
    "        \"Keep each value short (2–6 words). DO NOT return markdown or explanations.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"The language is: {detected_language}.\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=150\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Strip markdown/code block if GPT wraps it\n",
    "        if content.startswith(\"```\"):\n",
    "            content = content.strip(\"`\").strip()\n",
    "            # If there's still a language label, remove it\n",
    "            if content.startswith(\"json\"):\n",
    "                content = content[4:].strip()\n",
    "\n",
    "        # DEBUG PRINT\n",
    "        # print(\"GPT response (cleaned):\", content)\n",
    "\n",
    "        # Try parsing JSON\n",
    "        return json.loads(content)\n",
    "\n",
    "    except json.JSONDecodeError as je:\n",
    "        print(\"⚠️ Failed to parse GPT response as JSON.\")\n",
    "        print(\"Raw response:\\n\", content)\n",
    "        return {\n",
    "            \"culture\": detected_language,\n",
    "            \"art_form\": \"traditional art\",\n",
    "            \"motif\": \"cultural motif\",\n",
    "            \"script\": f\"{detected_language} script\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"GPT API Error: {e}\")\n",
    "        return {\n",
    "            \"culture\": detected_language,\n",
    "            \"art_form\": \"traditional art\",\n",
    "            \"motif\": \"cultural motif\",\n",
    "            \"script\": f\"{detected_language} script\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion and Canvas for Drawing Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/diffusers/pipelines/pipeline_loading_utils.py:242: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1 via `revision='fp16'` even though you can load it via `variant=`fp16`. Loading model variants via `revision='fp16'` is deprecated and will be removed in diffusers v1. Please use `variant='fp16'` instead.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...:  20%|██        | 1/5 [00:00<00:00,  5.54it/s]An error occurred while trying to fetch /Users/michael/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /Users/michael/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "An error occurred while trying to fetch /Users/michael/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /Users/michael/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|██████████| 5/5 [00:00<00:00,  8.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Stable Diffusion 2.1\n",
    "MODEL_ID = \"stabilityai/stable-diffusion-2-1\"\n",
    "\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    revision=\"fp16\"  # use float16 weights for efficiency\n",
    ")\n",
    "\n",
    "# Move to Apple Silicon GPU\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "pipeline.to(device)\n",
    "# Turn off NSFW filters due to overlapping stuff that may be detected as NSFW\n",
    "pipeline.safety_checker = None\n",
    "\n",
    "# Optimizations\n",
    "pipeline.enable_attention_slicing()\n",
    "pipeline.enable_vae_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dynamic_prompt():\n",
    "    global extracted_data\n",
    "\n",
    "    composition_style = extracted_data.get(\"composition_style\", \"balanced composition\")\n",
    "    cultural_info = fetch_cultural_prompt_info()\n",
    "\n",
    "    culture = cultural_info[\"culture\"]\n",
    "    art_form = cultural_info[\"art_form\"]\n",
    "    motif = cultural_info[\"motif\"]\n",
    "    script = cultural_info[\"script\"]\n",
    "\n",
    "    prompt = (\n",
    "        f\"A high-resolution digital painting of a symbolic {culture} scene or object, \"\n",
    "        f\"inspired by traditional {art_form}, \"\n",
    "        f\"featuring {motif}, layered with {script}, \"\n",
    "        f\"with a {composition_style} composition. \"\n",
    "        f\"Rendered in 768x768, cinematic lighting, textured brushwork, Van Gogh style, and borderless.\"\n",
    "    )\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def generate_image():\n",
    "    \"\"\"Generates an image and assigns it to an agent for gradual drawing.\"\"\"\n",
    "    prompt = build_dynamic_prompt()\n",
    "    print(f\"Generating Image with Prompt: {prompt}\")\n",
    "\n",
    "    # Generate the image using Stable Diffusion 2.1 at native 768x768 resolution\n",
    "    image = pipeline(\n",
    "        prompt,\n",
    "        height=768,\n",
    "        width=768,\n",
    "        num_inference_steps=30,  # slightly higher for better quality\n",
    "        guidance_scale=8.0\n",
    "    ).images[0]\n",
    "\n",
    "    # Save image\n",
    "    image_path = \"generated_image.png\"\n",
    "    image.save(image_path)\n",
    "    print(f\"Image saved as: {image_path}\")\n",
    "\n",
    "    return image_path \n",
    "\n",
    "def add_agent_for_image(image_path):\n",
    "    global agents\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGBA\")\n",
    "    image = image.resize((600, 600))\n",
    "\n",
    "    x = random.randint(0, 2560 - 600)\n",
    "    y = random.randint(0, 1440 - 600)\n",
    "\n",
    "    new_agent = Agent(image, x, y)\n",
    "    agents.append(new_agent)\n",
    "\n",
    "# Show live canvas    \n",
    "def show_live_canvas(canvas):\n",
    "    canvas_np = np.array(canvas.convert(\"RGB\"))[:, :, ::-1]  # PIL to OpenCV BGR\n",
    "    cv2.imshow(\"Live Canvas\", canvas_np)\n",
    "    key = cv2.waitKey(1)  # 1 ms delay to refresh window\n",
    "    if key == 27:  # Esc key to exit early\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def run_live_drawing_loop(steps=5000, delay=0.01):\n",
    "    for step in range(steps):\n",
    "        for agent in agents:\n",
    "            agent.update(canvas)\n",
    "\n",
    "        if step % 5 == 0:  # Show more frequently for smoother updates\n",
    "            if not show_live_canvas(canvas):\n",
    "                break  # Exit if Esc is pressed\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    cv2.destroyAllWindows()  # Close the window when done\n",
    "    canvas.save(\"final_collaborative_canvas.png\")\n",
    "    print(\"Saved as final_collaborative_canvas.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_processing():\n",
    "    \"\"\"Automates the full process based on user-uploaded image.\"\"\"\n",
    "    global extracted_data, canvas, agents  \n",
    "\n",
    "    # Ask the user to input an image file path\n",
    "    image_path = input(\"Enter the path to your handwriting image: \").strip()\n",
    "\n",
    "    # Extract handwritten text & detect language\n",
    "    extracted_text, detected_language = extract_text_from_handwriting(image_path)\n",
    "\n",
    "    if not extracted_text:\n",
    "        print(\"\\nFailed to extract text. Stopping process.\")\n",
    "        return None  # Stop if no text is found\n",
    "\n",
    "    # Translate text if needed\n",
    "    translated_text = translate_to_english(extracted_text) if detected_language.lower() != \"english\" else extracted_text\n",
    "\n",
    "    # Analyze emotion\n",
    "    text_analysis_data = analyze_emotion(translated_text)\n",
    "    detected_emotion = text_analysis_data.get(\"emotion\", \"Unknown\")\n",
    "    confidence_score = text_analysis_data.get(\"confidence\", 0.0)\n",
    "\n",
    "    # Store the extracted information in a global variable\n",
    "    extracted_data = {\n",
    "        \"extracted_text\": extracted_text,\n",
    "        \"language\": detected_language,\n",
    "        \"translated_text\": translated_text,\n",
    "        \"emotion\": detected_emotion,\n",
    "        \"confidence\": confidence_score,\n",
    "    }\n",
    "    \n",
    "    extracted_data[\"composition_style\"] = assign_composition_style()\n",
    "\n",
    "    extracted_data[\"visual_goal\"] = get_visual_goal()\n",
    "\n",
    "    # Print Final Summary\n",
    "    print(\"\\nAutomated Process Complete:\")\n",
    "    print(f\"Extracted Text: {extracted_data['extracted_text']}\")\n",
    "    print(f\"Detected Language: {extracted_data['language']}\")\n",
    "    print(f\"Translated Text: {extracted_data['translated_text'] if extracted_data['language'].lower() != 'english' else 'N/A'}\")\n",
    "    print(f\"Detected Emotion: {extracted_data['emotion']}\")\n",
    "    print(f\"Confidence Score: {extracted_data['confidence']:.2f}\")\n",
    "    print(f\"Assigned Composition Style: {extracted_data['composition_style']}\")\n",
    "    print(f\"Suggested Visual Goal: {extracted_data['visual_goal']}\")  \n",
    "    \n",
    "    agents.clear()\n",
    "    \n",
    "    generate_image()\n",
    "    \n",
    "    # Add to canvas and draw\n",
    "    add_agent_for_image(\"generated_image.png\")\n",
    "    run_live_drawing_loop()\n",
    "\n",
    "    # return extracted_data  # Return the full stored information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "canvas = Image.new(\"RGBA\", (2560, 1440), (255, 255, 255, 0))\n",
    "agents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Automated Process Complete:\n",
      "Extracted Text: حكاية الصياد مع الفقراء\n",
      "قالت بلغني أيها الملك السعيد أنه كان رجلًّا ذاعيالٍ في صيداق عن الأمسن وله ولدةٌ ثلاثة و ثلثة أولاد وهو فقير الحال وكان من عادته أنه يرمي شبكته كل يومٍ مرارًا لايغنمُ إنه خرج يومامن الأيام في وقت الظهر إلى الشارع ُ البحر وحط شبكته ومر إلى إذ استقرت في الماء فجمع خطًها فوجودها تقبلةً فأخذ يمش عليها في ذلك ذهب إلى البر و رددًا و ربطهانة ثم عرى وغمس في الماء حول الشبكة و مازال يب جى تطعمهم وأليس بها و أتى إلى الشارع كنت وجود فيها حرامياتنا لقنا ذلك حزن وزلَّا حول ولأ قال البالي العظيم ثم قال إن هذا الرزق عجيب وانشد يقول\n",
      "Detected Language: ar\n",
      "Translated Text: The language of the text is Arabic. Here's the translation to English:\n",
      "\n",
      "\"The tale of the fisherman with the poor\n",
      "It is said, O happy king, that there was a man with many children, living on his fishing claim, and he had three daughters and three sons. He was in poverty, and it was customary for him to cast his net several times each day without any gain. One day, at noon, he went down to the seashore and threw his net. He waited until it settled in the water, then gathered its lines to find them tangled. He walked along, pulling it until he reached the shore, tied it up, and then entered the water around the net. Despite trying hard to sustain them, he found nothing but disappointments. When he approached the shore to return, he found within his nets forbidden things, causing him sorrow. He sat down lamenting over his life’s troubles and recited a poem about the greatness of God, then said, 'This livelihood is mysterious,' and started to recite some verses.\"\n",
      "\n",
      "(Note: Translations from Arabic literature can have numerous interpretations; this translation aims to capture the essence of the story.)\n",
      "Detected Emotion: Sadness\n",
      "Confidence Score: 0.85\n",
      "Assigned Composition Style: Soft, Scattered & Faded\n",
      "Suggested Visual Goal: Arabesque, Calligraphy, Geometric Patterns\n",
      "Generating Image with Prompt: A high-resolution digital painting of a symbolic Arab scene or object, inspired by traditional Calligraphy, featuring Geometric patterns, layered with Arabic script, with a Soft, Scattered & Faded composition. Rendered in 768x768, cinematic lighting, textured brushwork, Van Gogh style, and borderless.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:37<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as: generated_image.png\n",
      "Saved as final_collaborative_canvas.png\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "automate_processing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
